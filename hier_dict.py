"""
Hierarchical Dictionary Builder for txtai 3-level embeddings
parent ‚Üí child ‚Üí exclude  +  auto-test (Precision@k)

Usage:
    from hier_dict import HierDict
    hd = HierDict(dial_emb, sent_emb, phrase_emb, texts)
    dictionary = hd.build()
    hd.test(k=5)           # –≤—ã–≤–æ–¥–∏—Ç Precision@k
"""
import json
import random
from collections import defaultdict
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd
import logging

logger = logging.getLogger(__name__)

class HierDict:
    def __init__(self, dial_embeddings, sent_embeddings, phrase_embeddings, texts):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è.
        
        Args:
            dial_embeddings: txtai.Embeddings (–¥–∏–∞–ª–æ–≥–∏)
            sent_embeddings: txtai.Embeddings (–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
            phrase_embeddings: txtai.Embeddings (—Ñ—Ä–∞–∑—ã)
            texts: List[str] ‚Äì –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∏–∞–ª–æ–≥–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤
        """
        self.dial_emb = dial_embeddings
        self.sent_emb = sent_embeddings
        self.phrase_emb = phrase_embeddings
        self.texts = texts
        
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω HierDict —Å {len(texts)} —Ç–µ–∫—Å—Ç–∞–º–∏")

    # ---------- 1. –ê–≤—Ç–æ-–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ ----------
    def _keywords(self, emb, texts, top_k=20):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç top-k —Å–ª–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π —á–∞—Å—Ç–æ—Ç–æ–π –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –¥–ª–∏–Ω–æ–π.
        
        Args:
            emb: txtai.Embeddings –æ–±—ä–µ–∫—Ç
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        """
        try:
            # –ü—Ä–æ—Å—Ç–æ —Å—á–∏—Ç–∞–µ–º TF + –≤–µ–∫—Ç–æ—Ä–Ω—É—é ¬´–≤–∞–∂–Ω–æ—Å—Ç—å¬ª
            words = [w.lower() for t in texts for w in t.split()]
            # –í–µ–∫—Ç–æ—Ä –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞
            unique = list(set(words))
            if not unique:
                return []
            
            w_vec = emb.embed(unique)
            # –°—É–º–º–∞ –∫–æ—Å–∏–Ω—É—Å–æ–≤ = ¬´—Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å¬ª
            centr = cosine_similarity(w_vec, w_vec).sum(axis=1)
            df = pd.DataFrame({"word": unique, "score": centr})
            
            keywords = df.sort_values("score", ascending=False).head(top_k)["word"].tolist()
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(keywords)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
            return keywords
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {e}")
            return []

    # ---------- 2. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ 3-—É—Ä–æ–≤–Ω—è ----------
    def build(self, out_file="smart_logger_dict.json"):
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è.
        
        Args:
            out_file: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä—è
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å parent, child –∏ exclude —Å–ª–æ–≤–∞–º–∏
        """
        try:
            logger.info("–ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è...")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—Ä–æ–≤–Ω—è
            parent = self._keywords(self.dial_emb, self.texts, 15)
            child = self._keywords(self.sent_emb, self.texts, 15)
            
            # Exclude = –∞–Ω—Ç–æ–Ω–∏–º—ã —á–µ—Ä–µ–∑ embeddings (—Å–∞–º—ã–µ –¥–∞–ª—ë–∫–∏–µ)
            all_w = list(set(" ".join(self.texts).lower().split()))
            if all_w:
                w_vec = self.phrase_emb.embed(all_w)
                parent_vec = self.phrase_emb.embed(parent)
                dist = cosine_similarity(parent_vec, w_vec).mean(axis=0)
                exclude = [all_w[i] for i in dist.argsort()[-10:]]  # 10 —Å–∞–º—ã—Ö ¬´–¥–∞–ª—å–Ω–∏—Ö¬ª
            else:
                exclude = []

            dictionary = {
                "parent": {"must": parent, "exclude": exclude},
                "child": {"must": child, "exclude": []},
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä—å
            with open(out_file, "w", encoding="utf8") as f:
                json.dump(dictionary, f, ensure_ascii=False, indent=2)
            
            logger.info(f"–°–ª–æ–≤–∞—Ä—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω ‚Üí {out_file}")
            logger.info(f"Parent —Å–ª–æ–≤: {len(parent)}")
            logger.info(f"Child —Å–ª–æ–≤: {len(child)}")
            logger.info(f"Exclude —Å–ª–æ–≤: {len(exclude)}")
            
            return dictionary
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä—è: {e}")
            return {}

    # ---------- 3. –ê–≤—Ç–æ-—Ç–µ—Å—Ç Precision@k ----------
    def test(self, k=5):
        """
        –°—á–∏—Ç–∞–µ–º Precision@k: —Å—á–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ k —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –ø–æ parent-—Ñ—Ä–∞–∑–∞–º.
        
        Args:
            k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –ó–Ω–∞—á–µ–Ω–∏–µ Precision@k
        """
        try:
            logger.info(f"–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ Precision@{k}...")
            
            # –£—Å–ª–æ–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            query_text = " ".join(self.texts[:50])
            parent_phrases = self.dial_emb.embed([query_text])
            results = self.dial_emb.search(query_text, limit=k)
            
            # –°—á–∏—Ç–∞–µ–º ¬´—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏¬ª —Ç–µ, –≥–¥–µ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã 1 —Å–ª–æ–≤–æ –∏–∑ parent
            parent_words = set(self._keywords(self.dial_emb, self.texts[:50], 10))
            relevant = sum(1 for r in results if any(w in r["text"] for w in parent_words))
            precision = relevant / k if k > 0 else 0
            
            logger.info(f"Precision@{k} = {precision:.2f}")
            logger.info(f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {relevant} –∏–∑ {k}")
            
            return precision
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return 0.0

    def get_statistics(self):
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Å–ª–æ–≤–∞—Ä—é.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        try:
            parent = self._keywords(self.dial_emb, self.texts, 15)
            child = self._keywords(self.sent_emb, self.texts, 15)
            
            return {
                "total_texts": len(self.texts),
                "parent_words": len(parent),
                "child_words": len(child),
                "parent_words_list": parent,
                "child_words_list": child
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}

    def export_to_smart_logger(self, output_file="smart_logger_dict.json"):
        """
        –≠–∫—Å–ø–æ—Ä—Ç —Å–ª–æ–≤–∞—Ä—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è Smart Logger.
        
        Args:
            output_file: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        try:
            dictionary = self.build(output_file)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è Smart Logger
            smart_logger_dict = {
                "metadata": {
                    "created_by": "CallCenter AI v3",
                    "version": "1.0",
                    "total_texts": len(self.texts),
                    "description": "–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤"
                },
                "dictionary": dictionary
            }
            
            with open(output_file, "w", encoding="utf8") as f:
                json.dump(smart_logger_dict, f, ensure_ascii=False, indent=2)
            
            logger.info(f"–°–ª–æ–≤–∞—Ä—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –¥–ª—è Smart Logger ‚Üí {output_file}")
            return output_file
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Smart Logger: {e}")
            return None


# ---------- 4. –ë—ã—Å—Ç—Ä—ã–π self-test ----------
if __name__ == "__main__":
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    import logging
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(level=logging.INFO)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    texts = [
        "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, –±–æ–Ω—É—Å –Ω–µ –Ω–∞—á–∏—Å–ª–∏–ª–∏, —Ö–æ—Ç—è –æ–±–µ—â–∞–ª–∏ –ø–æ–¥–∞—Ä–æ–∫.",
        "–û–ø–µ—Ä–∞—Ç–æ—Ä: –ü—Ä–æ–≤–µ—Ä—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –≤–µ—Ä–Ω—É—Å—å.",
        "–ö–ª–∏–µ–Ω—Ç: –°–ø–∞—Å–∏–±–æ, –∂–¥—É –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—é.",
        "–ü—Ä–æ–±–ª–µ–º–∞ —Å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–º, –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —É–∂–µ –¥–≤–∞ –¥–Ω—è.",
        "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞: –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–æ—É—Ç–µ—Ä.",
        "–ö–ª–∏–µ–Ω—Ç: –°–ø–∞—Å–∏–±–æ, –ø–æ–º–æ–≥–ª–æ!",
        "–•–æ—á—É –æ—Ç–º–µ–Ω–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É –Ω–∞ —É—Å–ª—É–≥–∏.",
        "–û–ø–µ—Ä–∞—Ç–æ—Ä: –û—Ñ–æ—Ä–º–ª—é –æ—Ç–º–µ–Ω—É, –¥–µ–Ω—å–≥–∏ –≤–µ—Ä–Ω—É—Ç—Å—è –≤ —Ç–µ—á–µ–Ω–∏–µ 5 –¥–Ω–µ–π.",
        "–ö–ª–∏–µ–Ω—Ç: –û—Ç–ª–∏—á–Ω–æ, —Å–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å."
    ]

    try:
        from txtai import Embeddings

        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ HierDict...")
        
        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        dial_emb = Embeddings({"path": "all-MiniLM-L6-v2", "content": True})
        sent_emb = Embeddings({"path": "all-MiniLM-L6-v2", "content": True})
        phr_emb = Embeddings({"path": "all-MiniLM-L6-v2", "content": True})

        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        dial_emb.index(texts)
        sent_emb.index([s for t in texts for s in t.split(".") if s.strip()])
        phr_emb.index([p for t in texts for p in t.split() if p.strip()])

        # –°–æ–∑–¥–∞–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å
        hd = HierDict(dial_emb, sent_emb, phr_emb, texts)
        
        # –°—Ç—Ä–æ–∏–º —Å–ª–æ–≤–∞—Ä—å
        dictionary = hd.build("test_dict.json")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º
        precision = hd.test(k=3)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = hd.get_statistics()
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è Smart Logger
        hd.export_to_smart_logger("smart_logger_test.json")
        
        print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        
    except ImportError:
        print("‚ùå txtai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install txtai")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
