#!/usr/bin/env python3
"""–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –¥–ª—è CallCenter AI v3."""

import sys
import os
import gc
import psutil
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

def get_system_memory_info():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–Ω–æ–π –ø–∞–º—è—Ç–∏."""
    memory = psutil.virtual_memory()
    return {
        'total': memory.total / 1024**3,
        'available': memory.available / 1024**3,
        'used': memory.used / 1024**3,
        'percent': memory.percent
    }

def get_gpu_memory_info():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∞–º—è—Ç–∏ GPU."""
    try:
        import torch
        if torch.cuda.is_available():
            return {
                'total': torch.cuda.get_device_properties(0).total_memory / 1024**3,
                'allocated': torch.cuda.memory_allocated() / 1024**3,
                'reserved': torch.cuda.memory_reserved() / 1024**3,
                'free': (torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved()) / 1024**3
            }
    except ImportError:
        pass
    return None

def test_model_loading():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π –ø–∞–º—è—Ç–∏."""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π –ø–∞–º—è—Ç–∏")
    print("=" * 60)
    
    # –°–∏—Å—Ç–µ–º–Ω–∞—è –ø–∞–º—è—Ç—å –¥–æ –∑–∞–≥—Ä—É–∑–∫–∏
    print("\nüìä –°–∏—Å—Ç–µ–º–Ω–∞—è –ø–∞–º—è—Ç—å –î–û –∑–∞–≥—Ä—É–∑–∫–∏:")
    sys_mem = get_system_memory_info()
    print(f"  üíæ –í—Å–µ–≥–æ: {sys_mem['total']:.1f} GB")
    print(f"  ‚úÖ –î–æ—Å—Ç—É–ø–Ω–æ: {sys_mem['available']:.1f} GB")
    print(f"  üìà –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {sys_mem['used']:.1f} GB ({sys_mem['percent']:.1f}%)")
    
    # GPU –ø–∞–º—è—Ç—å –¥–æ –∑–∞–≥—Ä—É–∑–∫–∏
    gpu_mem_before = get_gpu_memory_info()
    if gpu_mem_before:
        print(f"\nüéÆ GPU –ø–∞–º—è—Ç—å –î–û –∑–∞–≥—Ä—É–∑–∫–∏:")
        print(f"  üíæ –í—Å–µ–≥–æ: {gpu_mem_before['total']:.1f} GB")
        print(f"  ‚úÖ –°–≤–æ–±–æ–¥–Ω–æ: {gpu_mem_before['free']:.1f} GB")
        print(f"  üìà –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {gpu_mem_before['allocated']:.1f} GB")
    
    try:
        print(f"\nüîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        from sentence_transformers import SentenceTransformer
        import config
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        model = SentenceTransformer(config.EMBEDDING_MODEL_NAME, device="cuda")
        model.max_seq_length = 2048
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        
        # –°–∏—Å—Ç–µ–º–Ω–∞—è –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
        print(f"\nüìä –°–∏—Å—Ç–µ–º–Ω–∞—è –ø–∞–º—è—Ç—å –ü–û–°–õ–ï –∑–∞–≥—Ä—É–∑–∫–∏:")
        sys_mem_after = get_system_memory_info()
        print(f"  üíæ –í—Å–µ–≥–æ: {sys_mem_after['total']:.1f} GB")
        print(f"  ‚úÖ –î–æ—Å—Ç—É–ø–Ω–æ: {sys_mem_after['available']:.1f} GB")
        print(f"  üìà –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {sys_mem_after['used']:.1f} GB ({sys_mem_after['percent']:.1f}%)")
        print(f"  üìä –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {sys_mem_after['used'] - sys_mem['used']:.1f} GB")
        
        # GPU –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
        gpu_mem_after = get_gpu_memory_info()
        if gpu_mem_after:
            print(f"\nüéÆ GPU –ø–∞–º—è—Ç—å –ü–û–°–õ–ï –∑–∞–≥—Ä—É–∑–∫–∏:")
            print(f"  üíæ –í—Å–µ–≥–æ: {gpu_mem_after['total']:.1f} GB")
            print(f"  ‚úÖ –°–≤–æ–±–æ–¥–Ω–æ: {gpu_mem_after['free']:.1f} GB")
            print(f"  üìà –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {gpu_mem_after['allocated']:.1f} GB")
            print(f"  üìä –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {gpu_mem_after['allocated'] - gpu_mem_before['allocated']:.1f} GB")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–∞
        print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞...")
        test_text = "–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤."
        
        embedding = model.encode([test_text])
        print(f"‚úÖ –¢–µ–∫—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω, —Ä–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {embedding.shape}")
        
        # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å
        del model, embedding
        gc.collect()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
        print(f"\nüóëÔ∏è –ü–∞–º—è—Ç—å –ü–û–°–õ–ï –æ—á–∏—Å—Ç–∫–∏:")
        sys_mem_clean = get_system_memory_info()
        print(f"  üìà –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {sys_mem_clean['used']:.1f} GB ({sys_mem_clean['percent']:.1f}%)")
        
        gpu_mem_clean = get_gpu_memory_info()
        if gpu_mem_clean:
            print(f"  üéÆ GPU –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {gpu_mem_clean['allocated']:.1f} GB")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return False
    
    return True

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏."""
    print("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–∞–º—è—Ç–∏ CallCenter AI v3")
    print("=" * 60)
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫
        print("üìö –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫...")
        
        try:
            import torch
            print(f"‚úÖ PyTorch: {torch.__version__}")
            print(f"üéÆ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                print(f"üéÆ CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
                print(f"üéÆ GPU: {torch.cuda.get_device_name()}")
        except ImportError:
            print("‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        try:
            from sentence_transformers import SentenceTransformer
            print("‚úÖ SentenceTransformers –¥–æ—Å—Ç—É–ø–µ–Ω")
        except ImportError:
            print("‚ùå SentenceTransformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        try:
            import psutil
            print("‚úÖ psutil –¥–æ—Å—Ç—É–ø–µ–Ω")
        except ImportError:
            print("‚ùå psutil –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        if test_model_loading():
            print("\nüéâ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        else:
            print("\n‚ùå –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
            return 1
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
