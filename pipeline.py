"""–û–±—Ä–∞–±–æ—Ç–∫–∞ RTF-—Ñ–∞–π–ª–æ–≤, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞/–º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö, –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ (sentence-transformers GPU batch) –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ SQLite.
   –û–ë–ù–û–í–õ–ï–ù–û: —Ç–µ–ø–µ—Ä—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–ø–ª–∏–∫–∏ (utterances) –∏ –∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç–¥–µ–ª—å–Ω–æ.
   + –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –±–∞—Ç—á, TF32, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ, –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞, PYTORCH_CUDA_ALLOC_CONF.
"""

import os
import json
import sqlite3
import hashlib
import logging
from datetime import datetime
from pathlib import Path
from tqdm import tqdm
import gc

# === –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PYTORCH_CUDA_ALLOC_CONF –î–û –∏–º–ø–æ—Ä—Ç–∞ torch ===
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

# === sentence-transformers –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ ===
from sentence_transformers import SentenceTransformer
import torch

# === –í–∫–ª—é—á–∏—Ç—å TF32 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è ===
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

# === –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ RTF ===
from striprtf.striprtf import rtf_to_text

# === –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
import config

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
from utils import setup_logger
logger = setup_logger('Pipeline', config.LOGS_ROOT / "pipeline.log")

console_handler = logging.StreamHandler()
console_handler.setLevel(logging.WARNING)
console_formatter = logging.Formatter('üö® %(levelname)s - %(message)s')
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
logger.propagate = False

def log_to_file_only(msg):
    logger.info(msg)

def log(msg):
    logger.info(msg)

# === –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î ===
def ensure_db_initialized():
    log_to_file_only("–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ë–î...")
    try:
        conn = sqlite3.connect(config.DATABASE_PATH)
        cursor = conn.cursor()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ dialogs
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='dialogs';")
        if cursor.fetchone() is None:
            log_to_file_only("–¢–∞–±–ª–∏—Ü—ã –≤ –ë–î –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ó–∞–ø—É—Å–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏...")
            import init_db
            init_db.init_db()
            print("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ë–î –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞.")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã utterances, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS utterances (
                id TEXT PRIMARY KEY,
                dialog_id TEXT NOT NULL,
                speaker TEXT NOT NULL,
                text TEXT NOT NULL,
                turn_order INTEGER NOT NULL,
                FOREIGN KEY (dialog_id) REFERENCES dialogs(id) ON DELETE CASCADE
            );
        """)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã utterance_embeddings, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS utterance_embeddings (
                utterance_id TEXT PRIMARY KEY,
                vector BLOB NOT NULL,
                FOREIGN KEY (utterance_id) REFERENCES utterances(id) ON DELETE CASCADE
            );
        """)
        
        conn.commit()
        conn.close()
        log_to_file_only("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ë–î –∏ —Ç–∞–±–ª–∏—Ü utterances/utterance_embeddings –≤ –ø–æ—Ä—è–¥–∫–µ.")
    except Exception as e:
        log_to_file_only(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
        raise e

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ sentence-transformers ===
def load_embedding_model():
    log_to_file_only(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {config.EMBEDDING_MODEL_NAME} –Ω–∞ {config.EMBEDDING_MODEL_DEVICE}...")
    print(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {config.EMBEDDING_MODEL_NAME} –Ω–∞ {config.EMBEDDING_MODEL_DEVICE}...")
    
    device = torch.device(config.EMBEDDING_MODEL_DEVICE if torch.cuda.is_available() or config.EMBEDDING_MODEL_DEVICE != "cuda" else "cpu")
    
    model_kwargs = {}
    if config.EMBEDDING_MODEL_PRECISION == "float16" and device.type == "cuda":
        model_kwargs["torch_dtype"] = torch.float16
        
    model = SentenceTransformer(config.EMBEDDING_MODEL_NAME, device=str(device), model_kwargs=model_kwargs)
    model.max_seq_length = config.EMBEDDING_MODEL_MAX_LENGTH
    
    log_to_file_only(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}, —Ç–æ—á–Ω–æ—Å—Ç—å: {config.EMBEDDING_MODEL_PRECISION}")
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}, —Ç–æ—á–Ω–æ—Å—Ç—å: {config.EMBEDDING_MODEL_PRECISION}")
    return model, device

def hash_file(path: Path) -> str:
    return hashlib.md5(path.read_bytes()).hexdigest()

def extract_metadata_from_filename(filename_stem: str) -> dict:
    import re
    pattern = r'^(\d{4})(\d{2})(\d{2})(\d{2})(\d{2})(\d{2})_([A-Za-z0-9_]+)_([0-9]+)$'
    match = re.match(pattern, filename_stem)
    if match:
        year, month, day, hour, minute, second, operator_login, client_number = match.groups()
        if re.match(r'^\d{10,11}$', client_number):
            return {
                "date_from_filename": f"{year}-{month}-{day}",
                "time_from_filename": f"{hour}:{minute}:{second}",
                "operator_login_from_filename": operator_login,
                "client_number_from_filename": client_number
            }
    return {}

def clean_dialog_text_no_filter(text, file_metadata_from_name, file_id):
    import re
    from datetime import datetime
    lines = [line.rstrip() for line in text.splitlines() if line.rstrip()]
    if not lines:
        return [], file_metadata_from_name
    dialog_id = file_id
    dialog_datetime = None
    participants_line = None
    participants = {}
    dialog_type = "unknown"
    for i, line in enumerate(lines):
        id_datetime_match = re.match(r'^(\d+)\s*\((\d{2}\.\d{2}\.\d{4}\s\d{1,2}:\d{2}:\d{2})\)', line.strip())
        if id_datetime_match:
            dialog_id = id_datetime_match.group(1)
            try:
                dt_obj = datetime.strptime(id_datetime_match.group(2), '%d.%m.%Y %H:%M:%S')
                dialog_datetime = dt_obj.isoformat()
                dialog_type = "voice"
            except ValueError:
                pass
            if i + 1 < len(lines):
                participants_line = lines[i + 1].strip()
                p_match = re.search(r'([A-Za-z0-9@._\-]+)\s*(->|<-)\s*([0-9a-fA-F\-]+)', participants_line)
                if p_match:
                    op_raw = p_match.group(1)
                    arrow = p_match.group(2)
                    client_raw = p_match.group(3)
                    op_login = op_raw.split('@')[0] if '@' in op_raw else op_raw
                    participants["operator_login"] = op_login
                    participants["operator_raw"] = op_raw
                    participants["arrow"] = arrow
                    participants["client_id"] = client_raw
                    if client_raw.isdigit() and len(client_raw) >= 10:
                        participants["client_number"] = client_raw
            break
    if lines and "Rtf export" in lines[0] and "call(s)" in lines[0]:
        dialog_type = "chat"
    dialog_lines = []
    i = 0
    if participants_line:
        try:
            start_idx = lines.index(participants_line) + 1
            i = start_idx
        except ValueError:
            i = 0
    while i < len(lines):
        line = lines[i]
        if line.strip().lower() in ["rtf export, 1 call(s)", "–ø–æ—Ä–æ–≥ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: 5,00 —Å"]:
            i += 1
            continue
        if re.match(r'^\d+\s*\(\d{2}\.\d{2}\.\d{4}\s\d{1,2}:\d{2}:\d{2}\)', line.strip()) and i > 2:
             break
        time_match = re.search(r'\t(\d+:\d+:\d+)$', line)
        line_text = line
        line_time = None
        if time_match:
            line_time = time_match.group(1)
            line_text = line[:time_match.start()].rstrip("\t")
        line_text = line_text.strip()
        if not line_text:
            i += 1
            continue
        parts = line_text.split('\t', 1)
        potential_speaker = parts[0].strip()
        replica_text = parts[1].strip() if len(parts) > 1 else line_text
        if potential_speaker and len(potential_speaker) < 100 and replica_text:
            speaker = potential_speaker.split('@')[0] if '@' in potential_speaker else potential_speaker
            time_str = f" [{line_time}]" if line_time else ""
            dialog_lines.append(f"{speaker}: {replica_text}{time_str}")
        elif dialog_lines and replica_text:
            dialog_lines[-1] += f" {replica_text}"
        else:
             dialog_lines.append(line_text)
        i += 1

    final_metadata = file_metadata_from_name.copy()
    final_metadata.update({
        "dialog_id": dialog_id,
        "dialog_datetime": dialog_datetime,
        "participants_raw": participants_line,
        "dialog_type": dialog_type,
        "participants": participants
    })
    return dialog_lines, final_metadata  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ä–µ–ø–ª–∏–∫

# === –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ===
def process_thematic_folders():
    ensure_db_initialized()
    MODEL, device = load_embedding_model()
    
    log_to_file_only("üîç –ü–æ–∏—Å–∫ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø–∞–ø–æ–∫ –≤ Input...")
    theme_folders = [f for f in config.INPUT_ROOT.iterdir() if f.is_dir()]

    if not theme_folders:
        msg = "‚ö†Ô∏è –í –ø–∞–ø–∫–µ 'Input' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–¥–ø–∞–ø–æ–∫."
        log_to_file_only(msg)
        print(msg)
        return

    msg = f"üìÅ –ù–∞–π–¥–µ–Ω—ã —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞–ø–∫–∏: {[f.name for f in theme_folders]}"
    log_to_file_only(msg)
    print(msg)

    conn = sqlite3.connect(config.DATABASE_PATH)
    cursor = conn.cursor()

    total_new_dialogs = 0
    
    for theme_folder in theme_folders:
        theme_name = theme_folder.name
        msg = f"üìÇ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–º—ã: {theme_name}"
        log_to_file_only(msg)
        print(msg)
        
        theme_proc_path = config.PROCESSED_ROOT / theme_name
        theme_proc_path.mkdir(parents=True, exist_ok=True)
        
        already_processed_files = {hash_file(p): p.stem for p in theme_proc_path.glob("*.rtf")}
        files_to_process = [p for p in theme_folder.glob("*.rtf") if hash_file(p) not in already_processed_files]
        
        if not files_to_process:
            msg = f"‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –≤ '{theme_name}' —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã."
            log_to_file_only(msg)
            print(msg)
            continue

        msg = f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(files_to_process)} –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ '{theme_name}' –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏."
        log_to_file_only(msg)

        BATCH_SIZE = config.PIPELINE_BATCH_SIZE
        for i in tqdm(range(0, len(files_to_process), BATCH_SIZE), desc=f"–û–±—Ä–∞–±–æ—Ç–∫–∞ '{theme_name}' (–±–∞—Ç—á–∞–º–∏ –ø–æ {BATCH_SIZE})", unit="–±–∞—Ç—á"):
            batch_files = files_to_process[i:i + BATCH_SIZE]
            batch_dialogs_to_save = []
            batch_utterances_to_save = []
            batch_texts_to_encode = []
            batch_ids_for_embeddings = []
            
            # –≠—Ç–∞–ø 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
            for file in batch_files:
                try:
                    log_to_file_only(f"  üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {file.name}")
                    file_metadata = extract_metadata_from_filename(file.stem)
                    file_metadata["source_theme"] = theme_name
                    
                    raw_text = rtf_to_text(file.read_text(encoding="utf-8", errors="ignore"))
                    file_hash = hash_file(file)[:16]
                    dialog_lines, dialog_metadata = clean_dialog_text_no_filter(raw_text, file_metadata, file_hash)
                    
                    final_metadata = file_metadata.copy()
                    final_metadata.update(dialog_metadata)
                    dialog_id = final_metadata.get("dialog_id", file_hash)
                    
                    cursor.execute("SELECT id FROM dialogs WHERE id = ?", (dialog_id,))
                    if cursor.fetchone() is None:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–ª–æ–≥
                        batch_dialogs_to_save.append({
                            "id": dialog_id,
                            "text": "\n".join(dialog_lines),
                            "metadata": json.dumps(final_metadata, ensure_ascii=False),
                            "source_theme": theme_name,
                            "processed_at": datetime.now().isoformat()
                        })
                        total_new_dialogs += 1
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—É—é —Ä–µ–ø–ª–∏–∫—É
                        for idx, line in enumerate(dialog_lines):
                            if ": " in line:
                                speaker_part, text_part = line.split(": ", 1)
                                if " [" in text_part:
                                    text_part = text_part.split(" [")[0]
                            else:
                                speaker_part = "Unknown"
                                text_part = line
                            
                            utterance_id = f"{dialog_id}_u{idx+1:03d}"
                            batch_utterances_to_save.append({
                                "id": utterance_id,
                                "dialog_id": dialog_id,
                                "speaker": speaker_part,
                                "text": text_part,
                                "turn_order": idx + 1
                            })
                            batch_texts_to_encode.append(text_part)
                            batch_ids_for_embeddings.append(utterance_id)
                    
                    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
                    file.rename(theme_proc_path / file.name)
                        
                except Exception as e:
                    error_msg = f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file.name}: {e}"
                    log_to_file_only(error_msg)
                    print(error_msg)
                    if file.exists():
                        file.rename(theme_proc_path / file.name)

            # –≠—Ç–∞–ø 2: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤
            if batch_dialogs_to_save:
                try:
                    cursor.executemany("""
                        INSERT INTO dialogs (id, text, metadata, source_theme, processed_at)
                        VALUES (:id, :text, :metadata, :source_theme, :processed_at)
                    """, batch_dialogs_to_save)
                    conn.commit()
                except Exception as e:
                    log_to_file_only(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤: {e}")
                    conn.rollback()

            # –≠—Ç–∞–ø 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–ø–ª–∏–∫
            if batch_utterances_to_save:
                try:
                    cursor.executemany("""
                        INSERT INTO utterances (id, dialog_id, speaker, text, turn_order)
                        VALUES (:id, :dialog_id, :speaker, :text, :turn_order)
                    """, batch_utterances_to_save)
                    conn.commit()
                except Exception as e:
                    log_to_file_only(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–ø–ª–∏–∫: {e}")
                    conn.rollback()

            # === –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –î–õ–ò–ù –†–ï–ü–õ–ò–ö ===
            if batch_texts_to_encode:
                lengths = [len(text) for text in batch_texts_to_encode]
                log_to_file_only(f"  üìè –î–ª–∏–Ω—ã —Ä–µ–ø–ª–∏–∫: max={max(lengths)}, avg={sum(lengths)/len(lengths):.1f}")

            # –≠—Ç–∞–ø 4: –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ä–µ–ø–ª–∏–∫
            if batch_texts_to_encode:
                current_batch_size = min(BATCH_SIZE, len(batch_texts_to_encode))
                while current_batch_size > 0:
                    try:
                        log_to_file_only(f"  üß† –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ {len(batch_texts_to_encode)} —Ä–µ–ø–ª–∏–∫ –Ω–∞ {device} —Å –±–∞—Ç—á–µ–º {current_batch_size}...")
                        with torch.no_grad():
                            batch_embeddings = MODEL.encode(
                                batch_texts_to_encode,
                                convert_to_tensor=False,
                                show_progress_bar=False,
                                device=device,
                                batch_size=current_batch_size
                            )
                        break  # –£—Å–ø–µ—à–Ω–æ
                    except torch.cuda.OutOfMemoryError as e:
                        log_to_file_only(f"  ‚ö†Ô∏è CUDA OOM –ø—Ä–∏ –±–∞—Ç—á–µ {current_batch_size}. –ü—Ä–æ–±—É–µ–º —É–º–µ–Ω—å—à–∏—Ç—å...")
                        current_batch_size = max(1, current_batch_size // 2)
                        torch.cuda.empty_cache()
                        gc.collect()
                else:
                    log_to_file_only("  ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–ª–∏–∫–∏ –¥–∞–∂–µ —Å –±–∞—Ç—á–µ–º 1.")
                    conn.rollback()
                    continue

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
                try:
                    import pickle
                    embeddings_to_save = []
                    for uid, emb in zip(batch_ids_for_embeddings, batch_embeddings):
                        emb_blob = pickle.dumps(emb)
                        embeddings_to_save.append((uid, emb_blob))
                    
                    cursor.executemany("""
                        INSERT OR REPLACE INTO utterance_embeddings (utterance_id, vector)
                        VALUES (?, ?)
                    """, embeddings_to_save)
                    conn.commit()
                    
                    if device.type == "cuda":
                        torch.cuda.empty_cache()
                        gc.collect()
                        
                except Exception as e:
                    log_to_file_only(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏/—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ä–µ–ø–ª–∏–∫: {e}")
                    conn.rollback()

        msg = f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–º—ã: {theme_name}."
        log_to_file_only(msg)
        print(msg)

    conn.close()
    final_msg = f"üèÅ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø–∞–ø–æ–∫. –í—Å–µ–≥–æ –Ω–æ–≤—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤: {total_new_dialogs}"
    log_to_file_only(final_msg)
    print(final_msg)

if __name__ == "__main__":
    process_thematic_folders()