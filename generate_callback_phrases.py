# generate_callback_phrases.py
import sqlite3
import json
import logging
import time
import requests
import re
from typing import Optional, Dict, Any

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("llm_callback_errors.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
DB_PATH = "database.db"
conn = sqlite3.connect(DB_PATH)
cursor = conn.cursor()

# –ú–ò–ù–ò–ú–ê–õ–ò–°–¢–ò–ß–ù–´–ô –ü–†–û–ú–ü–¢ ‚Äî —Ç–æ–ª—å–∫–æ —Å—É—Ç—å, –±–µ–∑ –≤–æ–¥—ã
PROMPT_TEMPLATE = """–¢—ã ‚Äî JSON-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä. –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π. –§–æ—Ä–º–∞—Ç: {"error": true/false, "client_phrase": "...", "operator_phrase": "..."}

–ü—Ä–∞–≤–∏–ª–æ:
- error = true: –∫–ª–∏–µ–Ω—Ç –ß–Å–¢–ö–û —Å–∫–∞–∑–∞–ª "–ø–µ—Ä–µ–∑–≤–æ–Ω—é/—Å–≤—è–∂—É—Å—å/–Ω–∞–±–µ—Ä—É" –ë–ï–ó "–µ—Å–ª–∏/–º–æ–∂–µ—Ç/–∫–∞–∫-–Ω–∏–±—É–¥—å" ‚Üí –∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä –ù–ï –ø—Ä–µ–¥–ª–æ–∂–∏–ª –∑–≤–æ–Ω–æ–∫.
- error = false: –∫–ª–∏–µ–Ω—Ç –¥–∞–ª –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å –ò–õ–ò –æ–ø–µ—Ä–∞—Ç–æ—Ä –ø—Ä–µ–¥–ª–æ–∂–∏–ª –∑–≤–æ–Ω–æ–∫.

–§—Ä–∞–∑—ã ‚Äî –¥–æ—Å–ª–æ–≤–Ω–æ –∏–∑ –¥–∏–∞–ª–æ–≥–∞. –ù–∏—á–µ–≥–æ –ª–∏—à–Ω–µ–≥–æ.

–î–∏–∞–ª–æ–≥:
{dialog_text}
"""


def escape_curly_brackets(text: str) -> str:
    return text.replace("{", "{{").replace("}", "}}")


def extract_first_json(text: str) -> Optional[str]:
    start = text.find('{')
    if start == -1:
        return None
    for end in range(start + 1, len(text) + 1):
        try:
            candidate = text[start:end]
            json.loads(candidate)
            return candidate
        except json.JSONDecodeError:
            continue
    return None


def call_llm_with_retry(dialog_text: str, max_retries=2) -> Optional[Dict[str, Any]]:  # ‚Üê –£–º–µ–Ω—å—à–∏–ª –¥–æ 2 –ø–æ–ø—ã—Ç–æ–∫
    for attempt in range(max_retries):
        try:
            safe_dialog_text = escape_curly_brackets(dialog_text)
            prompt = PROMPT_TEMPLATE.format(dialog_text=safe_dialog_text)

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ api/generate ‚Äî –º–µ–Ω—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ ‚Üí –±—ã—Å—Ç—Ä–µ–µ
            response = requests.post(
                'http://localhost:11434/api/generate',
                json={
                    "model": "qwen2.5:1.5b-instruct-q4_K_M",
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "num_predict": 128,  # ‚Üê –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
                        "temperature": 0.1,  # ‚Üê –î–µ–ª–∞–µ–º –æ—Ç–≤–µ—Ç –±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º
                        "top_p": 0.9
                    }
                },
                timeout=30  # ‚Üê –£–º–µ–Ω—å—à–∞–µ–º —Ç–∞–π–º–∞—É—Ç
            )

            if response.status_code != 200:
                logging.warning(f"HTTP {response.status_code}: {response.text}")
                raise Exception(f"HTTP Error {response.status_code}")

            ollama_json = response.json()

            if "error" in ollama_json:
                error_msg = ollama_json["error"]
                logging.warning(f"Ollama error: {error_msg}")
                raise Exception(f"Ollama error: {error_msg}")

            raw_text = ollama_json.get("response", "").strip()
            logging.info(f"LLM raw response: {repr(raw_text)}")

            json_str = extract_first_json(raw_text)
            if not json_str:
                raise ValueError("No valid JSON found in response")

            result = json.loads(json_str)
            if "error" in result and "client_phrase" in result and "operator_phrase" in result:
                return result
            else:
                raise ValueError("Missing required keys in LLM JSON")

        except Exception as e:
            logging.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
            if attempt < max_retries - 1:
                time.sleep(0.5)  # ‚Üê –ö–æ—Ä–æ—Ç–∫–∞—è –ø–∞—É–∑–∞
            else:
                logging.error(f"LLM –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª–∞ –≤–∞–ª–∏–¥–Ω–æ –¥–ª—è –¥–∏–∞–ª–æ–≥–∞: {dialog_text[:100]}...")
                return None

    return None


# –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∏–∞–ª–æ–≥–∏
cursor.execute("SELECT id, text FROM dialogs")
dialogs = cursor.fetchall()

for i, (dialog_id, dialog_text) in enumerate(dialogs, 1):
    print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∏–∞–ª–æ–≥–∞ {i}/{len(dialogs)} (ID: {dialog_id})...")

    result = call_llm_with_retry(dialog_text)
    if not result:
        continue

    error = result["error"]
    client_phrase = result["client_phrase"].strip() if result["client_phrase"] else ""
    operator_phrase = result["operator_phrase"].strip() if result["operator_phrase"] else ""

    if error and client_phrase:
        cursor.execute("""
            INSERT OR IGNORE INTO callback_phrases (phrase, source, category, verified)
            VALUES (?, ?, ?, 0)
        """, (client_phrase, 'client_promise', 1))

    if not error:
        if "–µ—Å–ª–∏" in client_phrase or "–º–æ–∂–µ—Ç" in client_phrase or "–∫–∞–∫-–Ω–∏–±—É–¥—å" in client_phrase:
            cursor.execute("""
                INSERT OR IGNORE INTO callback_phrases (phrase, source, category, verified)
                VALUES (?, ?, ?, 0)
            """, (client_phrase, 'client_uncertain', 2))
        elif operator_phrase:
            cursor.execute("""
                INSERT OR IGNORE INTO callback_phrases (phrase, source, category, verified)
                VALUES (?, ?, ?, 0)
            """, (operator_phrase, 'operator_offer', 3))

    conn.commit()

conn.close()
print("‚úÖ –í—Å–µ –¥–∏–∞–ª–æ–≥–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã. –§—Ä–∞–∑—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü—É 'callback_phrases'.")
print("üìÑ –ü–æ–¥—Ä–æ–±–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏ —Å—ã—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã ‚Äî –≤ —Ñ–∞–π–ª–µ llm_callback_errors.log")